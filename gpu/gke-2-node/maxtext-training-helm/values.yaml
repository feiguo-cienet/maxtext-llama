# Trackable name for objects created from this Chart.
appPrefix: maxtext-training

MultiprocessingDistributed:
  # N Nodes
  replicas: 2

  # N GPU per Node
  nproc_per_node: 8

  # Defined this way in the event of MIG labels but should equal nproc_per_node.
  resources:
    limits:
      nvidia.com/gpu: 8

  # Helpful for heterogenous machine environments.
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: node.kubernetes.io/instance-type
                operator: In
                values:
                  - "g2-standard-96"

  # This is what actually runs in the container.
  # args:
  #   - python
  #   - train.py
  #   - --model=resnet50
  #   - --batch-size=64
  #   - --epochs=60
  #   - --lr=0.1
  #   - --momentum=0.9
  #   - --weight-decay=0.00002
  #   - --lr-step-size=30
  #   - --lr-gamma=0.1
  #   - --print-freq=1
  #   - --output-dir=/workspace/data
  #   - --amp

# Default image is on Docker hub now but may be pushed/pulled elsewhere.
createCredentials: false
imageCredentials: {}
  # registry: nvcr.io
  # username: $oauthtoken
  # password: "api-key"
  # email: "user@nvidia.com"

# This should be what was defined in the Docker Compose.
imagePullSecrets: []
  # - container-secret
baseImage:
  repository: us-docker.pkg.dev/hpc-test-2-438108/maxtext-base-image/llama2-7b-2node
  pullPolicy: Always
  tag: "latest"
